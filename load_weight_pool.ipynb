{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "# import apollocaffe\n",
    "# out = mx.symbol.load(\"googlenet-symbol.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pretrained_cnn = mx.nd.load(\"googlenet-0001.params\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(300L, 4L, 1L, 1L), (300L, 4L, 1L, 1L), (300L, 4L, 1L, 1L), (300L, 4L, 1L, 1L), (300L, 4L, 1L, 1L), (300L, 2L), (300L, 2L), (300L, 2L), (300L, 2L), (300L, 2L), (1L, 1024L, 15L, 20L)]\n"
     ]
    }
   ],
   "source": [
    "out = mx.symbol.load(\"googlenet-symbol.json\")\n",
    "arg_shapes, out_shapes, _ = out.infer_shape(data=(1,3,480,640),lstm_hidden_seed=(300,250),lstm_mem_seed=(300,250))\n",
    "print out_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arg_names = out.list_arguments()\n",
    "# for name in arg_names:\n",
    "#     if name == \"data\":\n",
    "#         continue\n",
    "#     key = \"arg:\" + name\n",
    "#     if key in pretrained:\n",
    "#         pretrained[key].copyto(arg_dict[name])\n",
    "#     else:\n",
    "#         print (\"SKIP arguments %s\" % name)\n",
    "# print arg_names\n",
    "# arg_names = arg_names + [\"rois\"]\n",
    "# arg_shapes = arg_shapes + [(1,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arg_dict = dict(zip(arg_names, [mx.nd.zeros(shape,ctx=mx.gpu(0)) for shape in arg_shapes]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ip_conf3_bias (2,)\n",
      "ip_bbox_unscaled4_weight (4, 250)\n",
      "ip_bbox_unscaled3_weight (4, 250)\n",
      "output_gate_weight (250, 1274)\n",
      "ip_bbox_unscaled2_bias (4,)\n",
      "ip_conf4_weight (2, 250)\n",
      "ip_conf3_weight (2, 250)\n",
      "forget_gate_weight (250, 1274)\n",
      "ip_bbox_unscaled4_bias (4,)\n",
      "input_value_weight (250, 1274)\n",
      "ip_conf0_weight (2, 250)\n",
      "ip_conf2_weight (2, 250)\n",
      "ip_conf1_weight (2, 250)\n",
      "ip_conf4_bias (2,)\n",
      "ip_conf0_bias (2,)\n",
      "input_gate_weight (250, 1274)\n",
      "ip_bbox_unscaled0_weight (4, 250)\n",
      "ip_bbox_unscaled1_bias (4,)\n",
      "ip_conf2_bias (2,)\n",
      "ip_conf1_bias (2,)\n",
      "ip_bbox_unscaled0_bias (4,)\n",
      "ip_bbox_unscaled3_bias (4,)\n",
      "ip_bbox_unscaled2_weight (4, 250)\n",
      "ip_bbox_unscaled1_weight (4, 250)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "lstm_content = pd.read_hdf(\"lstm.h5\",\"lstm\")\n",
    "param_name = list(lstm_content[\"param_name\"])\n",
    "param_ndarray = list(lstm_content[\"param_ndarray\"])\n",
    "\n",
    "param_dict = dict(zip(param_name,param_ndarray))\n",
    "for k,v in param_dict.items():\n",
    "    print k,v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for name in arg_names:\n",
    "    if name in [\"data\",\"lstm_mem_seed\",\"lstm_hidden_seed\"]:\n",
    "        continue\n",
    "    key = \"arg:\" + name\n",
    "    if key in pretrained_cnn:\n",
    "        pretrained_cnn[key].copyto(arg_dict[name])\n",
    "    elif \"input_value\" in name:\n",
    "#         print arg_dict[name].shape\n",
    "        mx.nd.array(param_dict[\"input_value_weight\"]).copyto(arg_dict[name])\n",
    "    elif \"output_gate\" in name:\n",
    "#         print arg_dict[name].shape\n",
    "#         print param_dict[\"output_gate_weight\"].shape\n",
    "        mx.nd.array(param_dict[\"output_gate_weight\"]).copyto(arg_dict[name])\n",
    "    elif \"input_gate\" in name:\n",
    "#         print arg_dict[name].shape\n",
    "        mx.nd.array(param_dict[\"input_gate_weight\"]).copyto(arg_dict[name])\n",
    "    elif \"forget_value\" in name:\n",
    "#         print arg_dict[name].shape\n",
    "        mx.nd.array(param_dict[\"forget_gate_weight\"]).copyto(arg_dict[name])\n",
    "    elif name in param_name:\n",
    "#         print arg_dict[name].shape\n",
    "        mx.nd.array(param_dict[name]).copyto(arg_dict[name])\n",
    "    else:\n",
    "        print (\"SKIP arguments %s\" % name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model = mx.model.FeedForward(out,num_epoch=100,learning_rate=0.01)\n",
    "mx.model.save_checkpoint(\"listen_mxnet_first\",epoch=0,symbol=out,arg_params=arg_dict,aux_params={})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import (annotation_jitter, image_to_h5_mx,\n",
    "                   annotation_to_h5, load_data_mean_mx)\n",
    "from utils.annolist import AnnotationLib as al\n",
    "import time\n",
    "import os\n",
    "from scipy.misc import imread,imsave\n",
    "import random\n",
    "from utils.annolist import AnnotationLib as al\n",
    "# from train import load_idl, forward\n",
    "from utils import (annotation_jitter,\n",
    "                   annotation_to_h5, Rect, stitch_rects)\n",
    "\n",
    "\n",
    "\n",
    "def load_idl(idlfile, data_mean, jitter=True):\n",
    "    \"\"\"Take the idlfile, data mean and net configuration and create a generator\n",
    "    that outputs a jittered version of a random image from the annolist\n",
    "    that is mean corrected.\"\"\"\n",
    "\n",
    "    annolist = al.parse(idlfile)\n",
    "    annos = [x for x in annolist]\n",
    "    for anno in annos:\n",
    "        anno.imageName = os.path.join(\n",
    "            os.path.dirname(os.path.realpath(idlfile)), anno.imageName)\n",
    "    while True:\n",
    "        random.shuffle(annos)\n",
    "        for anno in annos:\n",
    "#             if jitter:\n",
    "#                 jit_image, jit_anno = annotation_jitter(\n",
    "#                     anno, target_width=640,\n",
    "#                     target_height=480)\n",
    "#             else:\n",
    "            jit_image = imread(anno.imageName)\n",
    "#                 jit_anno = anno\n",
    "#             image = image_to_h5_mx(jit_image, data_mean, image_scaling=1.0)\n",
    "#             boxes, box_flags = annotation_to_h5(\n",
    "#                 jit_anno,640, 480,\n",
    "#                 64, 5)\n",
    "#             yield { \"image\": jit_image,'anno': jit_anno}\n",
    "            yield jit_image\n",
    "        break\n",
    "\n",
    "image_mean = load_data_mean_mx(\"./data/brainwash_mean.npy\", 640,480, image_scaling=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input_gen = load_idl(\"./data/brainwash/brainwash_train.idl\",image_mean, jitter = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import cv2\n",
    "max_len = 5\n",
    "\n",
    "executor = out.bind(ctx=mx.gpu(), args=arg_dict)\n",
    "e2eExcutor = namedtuple(\"e2eExcutor\",['executor','data','lstm_mem_seed','lstm_hidden_seed','bbox', 'conf',\"fm\",'arg_dict'])\n",
    "\n",
    "timeExcutor = e2eExcutor(executor = executor, \n",
    "                         data = arg_dict[\"data\"], \n",
    "                         lstm_mem_seed = arg_dict[\"lstm_mem_seed\"], \n",
    "                         lstm_hidden_seed = arg_dict[\"lstm_hidden_seed\"],\n",
    "                         bbox = executor.outputs[:max_len],\n",
    "                         conf = executor.outputs[max_len:],\n",
    "                         fm = executor.outputs[2*max_len],\n",
    "                         arg_dict=arg_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def overlap_union(x1,y1,x2,y2,x3,y3,x4,y4):\n",
    "#     SI = max(0, min(x2,x4)-max(x1,x3)) * max(0, min(y2,y4)-max(y1,y3))\n",
    "#     SU = (x2-x1)*(y2-y1) + (x4-x3)*(y4-y3) - SI + 0.0\n",
    "#     return SI/SU\n",
    "\n",
    "def generate_rois(batch_idx, rect, proposals):\n",
    "#     proposals =  []\n",
    "#     for rect in acc_rects:\n",
    "    left_topx = rect.cx - int(rect.width)\n",
    "    left_topy = rect.cy - int(rect.height/2)\n",
    "    proposals.append([batch_idx,left_topx,left_topy,left_topx+rect.width*2,left_topy+rect.height*5])\n",
    "#     return proposals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fm', 'rois']\n"
     ]
    }
   ],
   "source": [
    "rois = mx.symbol.Variable(name = \"rois\")\n",
    "fm = mx.symbol.Variable(name =  \"fm\")\n",
    "roi_pool = mx.symbol.ROIPooling(data = fm, rois = rois, pooled_size = (7,7), spatial_scale = 0.03125)\n",
    "pool5 = mx.symbol.Pooling(data = roi_pool, pool_type=\"max\", kernel=(7,7), stride=(1,1), name= \"pool5\")\n",
    "print pool5.list_arguments()\n",
    "\n",
    "rois_dict = dict(zip([\"rois\",\"fm\"], [mx.nd.zeros((1,5),ctx=mx.gpu(0)),mx.nd.zeros((1,1024,15,20),ctx=mx.gpu())]))\n",
    "feature_executor = pool5.bind(ctx=mx.gpu(),args=rois_dict)\n",
    "feature_extractor = namedtuple(\"feature_extracter\", [\"executor\",\"rois\",\"fm\",\"features\"])\n",
    "fexecutor = feature_extractor(executor = feature_executor,\n",
    "                            rois = rois_dict[\"rois\"],\n",
    "                             fm = rois_dict[\"fm\"],\n",
    "                             features = feature_executor.outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepocessd_image(raw_img, data_mean):\n",
    "    img_processed = image_to_h5_mx(raw_img, data_mean, image_scaling=1.0)\n",
    "    return {\"raw\": raw_img, \"image\": img_processed}\n",
    "\n",
    "def load_video_file(video_file, data_mean):\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    while not cap.isOpened():\n",
    "        cap = cv2.VideoCapture(video_file)\n",
    "        cv2.waitKey(1000)\n",
    "        print \"Wait for the header\"\n",
    "\n",
    "    pos_frame = cap.get(cv2.cv.CV_CAP_PROP_POS_FRAMES)\n",
    "    print \"frame count\", cap.get(cv2.cv.CV_CAP_PROP_FRAME_COUNT)\n",
    "    while True:\n",
    "        flag, frame = cap.read()\n",
    "        if flag:\n",
    "            pos_frame = cap.get(cv2.cv.CV_CAP_PROP_POS_FRAMES)\n",
    "            raw_img = frame[-480:, :640, :]\n",
    "            \n",
    "            res = prepocessd_image(raw_img, data_mean)\n",
    "            res['frame_no'] = pos_frame\n",
    "            yield res\n",
    "\n",
    "        else:\n",
    "            # The next frame is not ready, so we try to read it again\n",
    "            cap.set(cv2.cv.CV_CAP_PROP_POS_FRAMES, pos_frame-1)\n",
    "            print \"frame is not ready\"\n",
    "            # It is better to wait for a while for the next frame to be ready\n",
    "            break\n",
    "\n",
    "        if cv2.waitKey(10) == 27:\n",
    "            break\n",
    "        if cap.get(cv2.cv.CV_CAP_PROP_POS_FRAMES) == cap.get(cv2.cv.CV_CAP_PROP_FRAME_COUNT):\n",
    "            # If the number of captured frames is equal to the total number of frames,\n",
    "            # we stop\n",
    "            break\n",
    "    cap.release()\n",
    "\n",
    "# det_file = open(\"./tianmulu/det.txt\")\n",
    "\n",
    "# def image_generator(img_file, data_mean):\n",
    "#     img_list = open(img_file).readlines()\n",
    "    \n",
    "#     frame = 1\n",
    "#     for i in img_list:\n",
    "#         img_pair = i.strip().split(\" \")\n",
    "#         raw_img = imread(img_pair[0])\n",
    "#         im = image_to_h5_mx(raw_img, data_mean, image_scaling=1.0)\n",
    "#         num = int(img_pair[1])\n",
    "#         p = []\n",
    "#         for j in range(num):\n",
    "#             det = det_file.readline().strip()\n",
    "#             p.append([int(x) for x in det.split(\" \")])\n",
    "#         yield {\"image\":im,\"raw\":raw_img, \"proposal\":p, \"frame_no\":frame}\n",
    "#         frame = frame + 1\n",
    "\n",
    "# def generate_rois2(batch_idx, rect, proposals):\n",
    "# #     proposals =  []\n",
    "# #     for rect in acc_rects:\n",
    "#     left_topx = rect[0]\n",
    "#     left_topy = rect[1]\n",
    "#     proposals.append([batch_idx,left_topx,left_topy,left_topx+rect[2],left_topy+rect[3]])\n",
    "#     return proposals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_file = \"./Video5.avi\"\n",
    "# img_file = \"./tianmulu/img_list.txt\"\n",
    "input_gen = load_video_file(video_file, image_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_width = 20\n",
    "grid_height = 15\n",
    "img_width = 640\n",
    "img_height = 480\n",
    "import numpy as np\n",
    "num = 0\n",
    "\n",
    "# img = input_gen.next()\n",
    "# for img_set in input_gen:\n",
    "#     img_set = input_gen.next()\n",
    "#     if num%100 == 0:\n",
    "# img = img_set[\"image\"]\n",
    "# anno = img_set[\"anno\"]\n",
    "\n",
    "#     count_anno += len(anno.rects)\n",
    "#     print type(anno)\n",
    "# writer = \"ll.txt\"\n",
    "# f = open(\"features.txt\",\"w\")\n",
    "\n",
    "# bbox_path = './tianmulu/bboxes/'\n",
    "# feature_path = './tianmulu/features/'\n",
    "log_file = \"./tianmulu/bbox.txt\"\n",
    "\n",
    "def forward_test(im_dict):\n",
    "#     im_input = image_to_h5_mx(img, image_mean, image_scaling=1.0)\n",
    "    \n",
    "    timeExcutor.data[:] = mx.nd.array(im_dict[\"image\"],mx.gpu())\n",
    "    timeExcutor.lstm_mem_seed[:] = mx.nd.zeros((300,250),mx.gpu())\n",
    "    timeExcutor.lstm_hidden_seed[:] =  mx.nd.zeros((300,250),mx.gpu())\n",
    "\n",
    "    timeExcutor.executor.forward()\n",
    "    bbox_list = [timeExcutor.bbox[idx].asnumpy() for idx in range(max_len)]\n",
    "    conf_list = [timeExcutor.conf[idx].asnumpy() for idx in range(max_len)]\n",
    "\n",
    "    all_rects = [[[] for x in range(grid_width)] for y in range(grid_height)]\n",
    "    pix_per_w = img_width/grid_width\n",
    "    pix_per_h = img_height/grid_height\n",
    "    for n in range(len(bbox_list)):\n",
    "        for k in range(grid_height * grid_width):\n",
    "            #print k,n,\"k n\"\n",
    "            y = int(k / grid_width)\n",
    "            x = int(k % grid_width)\n",
    "            bbox = bbox_list[n][k]\n",
    "            conf = conf_list[n][k,1].flatten()[0]\n",
    "            abs_cx = pix_per_w/2 + pix_per_w*x + int(bbox[0,0,0])\n",
    "            abs_cy = pix_per_h/2 + pix_per_h*y + int(bbox[1,0,0])\n",
    "            w = bbox[2,0,0]\n",
    "            h = bbox[3,0,0]\n",
    "            #print x,y\n",
    "            all_rects[y][x].append(Rect(abs_cx,abs_cy,w,h,conf))\n",
    "    acc_rects = stitch_rects(all_rects)\n",
    "#     print len(acc_rects)\n",
    "    proposals = []\n",
    "    img = im_dict[\"raw\"]\n",
    "    for rect in acc_rects:\n",
    "        generate_rois(0, rect, proposals)\n",
    "        cv2.rectangle(img, (proposals[-1][1],proposals[-1][2]),(proposals[-1][3],proposals[-1][4]),color=(0,0,255),thickness=2)\n",
    "    imsave(\"./check2/%i.jpg\"%int(im_dict[\"frame_no\"]), img)\n",
    "    fexecutor.fm[:] = timeExcutor.fm\n",
    "    pos_frame = int(im_dict[\"frame_no\"])\n",
    "    l = open(log_file, \"a\")\n",
    "    for p in proposals:\n",
    "        fexecutor.rois[:] = mx.nd.array(p,mx.gpu()).reshape((1,5))\n",
    "#         print p\n",
    "        fexecutor.executor.forward()\n",
    "        l.write(str(pos_frame)+' '+str(p[1])+' '+str(p[2])+' '+str(p[3])+' '+str(p[4])+' ')\n",
    "        np.savetxt(l, fexecutor.features.asnumpy().reshape(1,-1),fmt = \"%.8g\")\n",
    "    l.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def updatefig(*args):\n",
    "    new_frame = forward_test(input_gen.next())\n",
    "    im.set_array(new_frame)\n",
    "    output_video.write(new_frame)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame count 52399.0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import colormaps as cmaps\n",
    "# fourcc = cv2.cv.CV_FOURCC(*'XVID')\n",
    "# output_video = cv2.VideoWriter(video_file+'out.avi',fourcc, 20.0, (640,480))\n",
    "\n",
    "# # output_label_path = './tianmulu/labels/'\n",
    "# # output_image_path = './tianmulu/images/'\n",
    "# # fig = \n",
    "# fig = plt.figure()\n",
    "# im = plt.imshow(forward_test(input_gen.next()), animated=True)\n",
    "# ani = animation.FuncAnimation(fig, updatefig, interval=1, blit=True)\n",
    "# plt.show()\n",
    "for i in range(1000):\n",
    "    forward_test(input_gen.next())\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grid_width = 20\n",
    "# grid_height = 15\n",
    "# img_width = 640\n",
    "# img_height = 480\n",
    "\n",
    "# start = time.clock()\n",
    "# num = 0\n",
    "\n",
    "# img = input_gen.next()\n",
    "# # for img_set in input_gen:\n",
    "# #     img_set = input_gen.next()\n",
    "# #     if num%100 == 0:\n",
    "# # img = img_set[\"image\"]\n",
    "# # anno = img_set[\"anno\"]\n",
    "\n",
    "# #     count_anno += len(anno.rects)\n",
    "# #     print type(anno)\n",
    "# im_input = image_to_h5_mx(img, image_mean, image_scaling=1.0)\n",
    "\n",
    "# timeExcutor.data[:] = mx.nd.array(im_input,mx.gpu())\n",
    "# timeExcutor.lstm_mem_seed[:] = mx.nd.zeros((300,250),mx.gpu())\n",
    "# timeExcutor.lstm_hidden_seed[:] =  mx.nd.zeros((300,250),mx.gpu())\n",
    "\n",
    "# timeExcutor.executor.forward()\n",
    "\n",
    "# bbox_list = [timeExcutor.bbox[idx].asnumpy() for idx in range(max_len)]\n",
    "# conf_list = [timeExcutor.conf[idx].asnumpy() for idx in range(max_len)]\n",
    "\n",
    "# all_rects = [[[] for x in range(grid_width)] for y in range(grid_height)]\n",
    "# pix_per_w = img_width/grid_width\n",
    "# pix_per_h = img_height/grid_height\n",
    "# for n in range(len(bbox_list)):\n",
    "#     for k in range(grid_height * grid_width):\n",
    "#         #print k,n,\"k n\"\n",
    "#         y = int(k / grid_width)\n",
    "#         x = int(k % grid_width)\n",
    "#         bbox = bbox_list[n][k]\n",
    "#         conf = conf_list[n][k,1].flatten()[0]\n",
    "#         abs_cx = pix_per_w/2 + pix_per_w*x + int(bbox[0,0,0])\n",
    "#         abs_cy = pix_per_h/2 + pix_per_h*y + int(bbox[1,0,0])\n",
    "#         w = bbox[2,0,0]\n",
    "#         h = bbox[3,0,0]\n",
    "#         #print x,y\n",
    "#         all_rects[y][x].append(Rect(abs_cx,abs_cy,w,h,conf))\n",
    "\n",
    "# # for rect in acc_rects:\n",
    "\n",
    "# #     if rect.true_confidence < 0.6:\n",
    "# #         continue\n",
    "# acc_rects = stitch_rects(all_rects)\n",
    "# proposals = []\n",
    "# print len(acc_rects)\n",
    "\n",
    "# for rect in acc_rects:\n",
    "#     if rect.true_confidence < 0.6:\n",
    "#         continue\n",
    "#     generate_rois(0, rect, proposals)\n",
    "#     cv2.rectangle(img, (rect.cx-int(rect.width/2), rect.cy-int(rect.height/2)),\\\n",
    "#      (rect.cx+int(rect.width/2), rect.cy+int(rect.height/2)),color=(0,0,255),thickness=2)\n",
    "# print len(proposals)\n",
    "# # print len(acc_rects)\n",
    "# # fexecutor.rois[:] = mx.nd.array(generate_rois(0,acc_rects),mx.gpu())\n",
    "# # print rois_dict[\"rois\"].shape\n",
    "# # # fexecutor.fm[:] = generate_rois(0,acc_rects)\n",
    "# # rois_dict[\"fm\"] = timeExcutor.fm\n",
    "\n",
    "# # # for rect in acc_rects:\n",
    "\n",
    "# #     if rect.true_confidence < 0.6:fm[:]\n",
    "# #         continue\n",
    "# #     cv2.rectangle(img, (rect.cx-int(rect.width/2), rect.cy-int(rect.height/2)),\\\n",
    "# #      (rect.cx+int(rect.width/2), rect.cy+int(rect.height/2)),color=(0,0,255),thickness=2)\n",
    "# # imsave(\"./mxnet/%i.jpg\"% i, img)\n",
    "# # print time.clock() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'proposals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-7de0b77176b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"ll.txt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mproposals\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mfexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrois\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mfexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'proposals' is not defined"
     ]
    }
   ],
   "source": [
    "# fexecutor.executor.forward()\n",
    "# print fexecutor.features.shape\n",
    "import numpy as np\n",
    "fexecutor.fm[:] = timeExcutor.fm\n",
    "writer = \"ll.txt\"\n",
    "f = open(writer,\"w\")\n",
    "for p in proposals:\n",
    "    fexecutor.rois[:] = mx.nd.array(p,mx.gpu()).reshape((1,5))\n",
    "    fexecutor.executor.forward()\n",
    "    print np.max(fexecutor.features.asnumpy())\n",
    "#     for a in \n",
    "    np.savetxt(f, fexecutor.features.asnumpy().reshape(1,-1),fmt = \"%.8g\")\n",
    "    f.write(\"\\n\\n\\n\\n\")\n",
    "    print \"haha\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = mx.nd.array([1,2,3]).reshape((1,3))\n",
    "# help (mx.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1L, 3L)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
