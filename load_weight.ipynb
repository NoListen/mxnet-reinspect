{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "# import apollocaffe\n",
    "# out = mx.symbol.load(\"googlenet-symbol.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pretrained_cnn = mx.nd.load(\"googlenet-0001.params\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(300L, 4L, 1L, 1L), (300L, 4L, 1L, 1L), (300L, 4L, 1L, 1L), (300L, 4L, 1L, 1L), (300L, 4L, 1L, 1L), (300L, 2L), (300L, 2L), (300L, 2L), (300L, 2L), (300L, 2L), (1L, 1024L, 15L, 20L)]\n"
     ]
    }
   ],
   "source": [
    "out = mx.symbol.load(\"googlenet-symbol.json\")\n",
    "arg_shapes, out_shapes, _ = out.infer_shape(data=(1,3,480,640),lstm_hidden_seed=(300,250),lstm_mem_seed=(300,250))\n",
    "print out_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'conv1_7x7_s2_weight', 'conv1_7x7_s2_bias', 'conv2_3x3_reduce_weight', 'conv2_3x3_reduce_bias', 'conv2_3x3_weight', 'conv2_3x3_bias', 'inception_3a_1x1_weight', 'inception_3a_1x1_bias', 'inception_3a_3x3_reduce_weight', 'inception_3a_3x3_reduce_bias', 'inception_3a_3x3_weight', 'inception_3a_3x3_bias', 'inception_3a_5x5_reduce_weight', 'inception_3a_5x5_reduce_bias', 'inception_3a_5x5_weight', 'inception_3a_5x5_bias', 'inception_3a_pool_proj_weight', 'inception_3a_pool_proj_bias', 'inception_3b_1x1_weight', 'inception_3b_1x1_bias', 'inception_3b_3x3_reduce_weight', 'inception_3b_3x3_reduce_bias', 'inception_3b_3x3_weight', 'inception_3b_3x3_bias', 'inception_3b_5x5_reduce_weight', 'inception_3b_5x5_reduce_bias', 'inception_3b_5x5_weight', 'inception_3b_5x5_bias', 'inception_3b_pool_proj_weight', 'inception_3b_pool_proj_bias', 'inception_4a_1x1_weight', 'inception_4a_1x1_bias', 'inception_4a_3x3_reduce_weight', 'inception_4a_3x3_reduce_bias', 'inception_4a_3x3_weight', 'inception_4a_3x3_bias', 'inception_4a_5x5_reduce_weight', 'inception_4a_5x5_reduce_bias', 'inception_4a_5x5_weight', 'inception_4a_5x5_bias', 'inception_4a_pool_proj_weight', 'inception_4a_pool_proj_bias', 'inception_4b_1x1_weight', 'inception_4b_1x1_bias', 'inception_4b_3x3_reduce_weight', 'inception_4b_3x3_reduce_bias', 'inception_4b_3x3_weight', 'inception_4b_3x3_bias', 'inception_4b_5x5_reduce_weight', 'inception_4b_5x5_reduce_bias', 'inception_4b_5x5_weight', 'inception_4b_5x5_bias', 'inception_4b_pool_proj_weight', 'inception_4b_pool_proj_bias', 'inception_4c_1x1_weight', 'inception_4c_1x1_bias', 'inception_4c_3x3_reduce_weight', 'inception_4c_3x3_reduce_bias', 'inception_4c_3x3_weight', 'inception_4c_3x3_bias', 'inception_4c_5x5_reduce_weight', 'inception_4c_5x5_reduce_bias', 'inception_4c_5x5_weight', 'inception_4c_5x5_bias', 'inception_4c_pool_proj_weight', 'inception_4c_pool_proj_bias', 'inception_4d_1x1_weight', 'inception_4d_1x1_bias', 'inception_4d_3x3_reduce_weight', 'inception_4d_3x3_reduce_bias', 'inception_4d_3x3_weight', 'inception_4d_3x3_bias', 'inception_4d_5x5_reduce_weight', 'inception_4d_5x5_reduce_bias', 'inception_4d_5x5_weight', 'inception_4d_5x5_bias', 'inception_4d_pool_proj_weight', 'inception_4d_pool_proj_bias', 'inception_4e_1x1_weight', 'inception_4e_1x1_bias', 'inception_4e_3x3_reduce_weight', 'inception_4e_3x3_reduce_bias', 'inception_4e_3x3_weight', 'inception_4e_3x3_bias', 'inception_4e_5x5_reduce_weight', 'inception_4e_5x5_reduce_bias', 'inception_4e_5x5_weight', 'inception_4e_5x5_bias', 'inception_4e_pool_proj_weight', 'inception_4e_pool_proj_bias', 'inception_5a_1x1_weight', 'inception_5a_1x1_bias', 'inception_5a_3x3_reduce_weight', 'inception_5a_3x3_reduce_bias', 'inception_5a_3x3_weight', 'inception_5a_3x3_bias', 'inception_5a_5x5_reduce_weight', 'inception_5a_5x5_reduce_bias', 'inception_5a_5x5_weight', 'inception_5a_5x5_bias', 'inception_5a_pool_proj_weight', 'inception_5a_pool_proj_bias', 'inception_5b_1x1_weight', 'inception_5b_1x1_bias', 'inception_5b_3x3_reduce_weight', 'inception_5b_3x3_reduce_bias', 'inception_5b_3x3_weight', 'inception_5b_3x3_bias', 'inception_5b_5x5_reduce_weight', 'inception_5b_5x5_reduce_bias', 'inception_5b_5x5_weight', 'inception_5b_5x5_bias', 'inception_5b_pool_proj_weight', 'inception_5b_pool_proj_bias', 'post_fc7_conv_weight', 'post_fc7_conv_bias', 'lstm_hidden_seed', 'output_gate_values0_weight', 'lstm_mem_seed', 'input_values0_weight', 'input_gate_values0_weight', 'ip_bbox_unscaled0_weight', 'ip_bbox_unscaled0_bias', 'output_gate_values1_weight', 'input_values1_weight', 'input_gate_values1_weight', 'ip_bbox_unscaled1_weight', 'ip_bbox_unscaled1_bias', 'output_gate_values2_weight', 'input_values2_weight', 'input_gate_values2_weight', 'ip_bbox_unscaled2_weight', 'ip_bbox_unscaled2_bias', 'output_gate_values3_weight', 'input_values3_weight', 'input_gate_values3_weight', 'ip_bbox_unscaled3_weight', 'ip_bbox_unscaled3_bias', 'output_gate_values4_weight', 'input_values4_weight', 'input_gate_values4_weight', 'ip_bbox_unscaled4_weight', 'ip_bbox_unscaled4_bias', 'ip_conf0_weight', 'ip_conf0_bias', 'ip_conf1_weight', 'ip_conf1_bias', 'ip_conf2_weight', 'ip_conf2_bias', 'ip_conf3_weight', 'ip_conf3_bias', 'ip_conf4_weight', 'ip_conf4_bias']\n"
     ]
    }
   ],
   "source": [
    "arg_names = out.list_arguments()\n",
    "# for name in arg_names:\n",
    "#     if name == \"data\":\n",
    "#         continue\n",
    "#     key = \"arg:\" + name\n",
    "#     if key in pretrained:\n",
    "#         pretrained[key].copyto(arg_dict[name])\n",
    "#     else:\n",
    "#         print (\"SKIP arguments %s\" % name)\n",
    "print arg_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arg_dict = dict(zip(arg_names, [mx.nd.zeros(shape,ctx=mx.gpu(0)) for shape in arg_shapes]))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print arg_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ip_conf3_bias (2,)\n",
      "ip_bbox_unscaled4_weight (4, 250)\n",
      "ip_bbox_unscaled3_weight (4, 250)\n",
      "output_gate_weight (250, 1274)\n",
      "ip_bbox_unscaled2_bias (4,)\n",
      "ip_conf4_weight (2, 250)\n",
      "ip_conf3_weight (2, 250)\n",
      "forget_gate_weight (250, 1274)\n",
      "ip_bbox_unscaled4_bias (4,)\n",
      "input_value_weight (250, 1274)\n",
      "ip_conf0_weight (2, 250)\n",
      "ip_conf2_weight (2, 250)\n",
      "ip_conf1_weight (2, 250)\n",
      "ip_conf4_bias (2,)\n",
      "ip_conf0_bias (2,)\n",
      "input_gate_weight (250, 1274)\n",
      "ip_bbox_unscaled0_weight (4, 250)\n",
      "ip_bbox_unscaled1_bias (4,)\n",
      "ip_conf2_bias (2,)\n",
      "ip_conf1_bias (2,)\n",
      "ip_bbox_unscaled0_bias (4,)\n",
      "ip_bbox_unscaled3_bias (4,)\n",
      "ip_bbox_unscaled2_weight (4, 250)\n",
      "ip_bbox_unscaled1_weight (4, 250)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "lstm_content = pd.read_hdf(\"lstm.h5\",\"lstm\")\n",
    "param_name = list(lstm_content[\"param_name\"])\n",
    "param_ndarray = list(lstm_content[\"param_ndarray\"])\n",
    "\n",
    "param_dict = dict(zip(param_name,param_ndarray))\n",
    "for k,v in param_dict.items():\n",
    "    print k,v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for name in arg_names:\n",
    "    if name in [\"data\",\"lstm_mem_seed\",\"lstm_hidden_seed\"]:\n",
    "        continue\n",
    "    key = \"arg:\" + name\n",
    "    if key in pretrained_cnn:\n",
    "        pretrained_cnn[key].copyto(arg_dict[name])\n",
    "    elif \"input_value\" in name:\n",
    "#         print arg_dict[name].shape\n",
    "        mx.nd.array(param_dict[\"input_value_weight\"]).copyto(arg_dict[name])\n",
    "    elif \"output_gate\" in name:\n",
    "#         print arg_dict[name].shape\n",
    "#         print param_dict[\"output_gate_weight\"].shape\n",
    "        mx.nd.array(param_dict[\"output_gate_weight\"]).copyto(arg_dict[name])\n",
    "    elif \"input_gate\" in name:\n",
    "#         print arg_dict[name].shape\n",
    "        mx.nd.array(param_dict[\"input_gate_weight\"]).copyto(arg_dict[name])\n",
    "    elif \"forget_value\" in name:\n",
    "#         print arg_dict[name].shape\n",
    "        mx.nd.array(param_dict[\"forget_gate_weight\"]).copyto(arg_dict[name])\n",
    "    elif name in param_name:\n",
    "#         print arg_dict[name].shape\n",
    "        mx.nd.array(param_dict[name]).copyto(arg_dict[name])\n",
    "    else:\n",
    "        print (\"SKIP arguments %s\" % name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model = mx.model.FeedForward(out,num_epoch=100,learning_rate=0.01)\n",
    "mx.model.save_checkpoint(\"listen_mxnet_first\",epoch=0,symbol=out,arg_params=arg_dict,aux_params={})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ls = mx.nd.load(\"listen_mxnet_first-0000.params\")\n",
    "# print ls.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import (annotation_jitter, image_to_h5_mx,\n",
    "                   annotation_to_h5, load_data_mean_mx)\n",
    "from utils.annolist import AnnotationLib as al\n",
    "import time\n",
    "import os\n",
    "from scipy.misc import imread,imsave\n",
    "import random\n",
    "from utils.annolist import AnnotationLib as al\n",
    "# from train import load_idl, forward\n",
    "from utils import (annotation_jitter,\n",
    "                   annotation_to_h5, Rect, stitch_rects)\n",
    "\n",
    "\n",
    "\n",
    "def load_idl(idlfile, data_mean, jitter=True):\n",
    "    \"\"\"Take the idlfile, data mean and net configuration and create a generator\n",
    "    that outputs a jittered version of a random image from the annolist\n",
    "    that is mean corrected.\"\"\"\n",
    "\n",
    "    annolist = al.parse(idlfile)\n",
    "    annos = [x for x in annolist]\n",
    "    for anno in annos:\n",
    "        anno.imageName = os.path.join(\n",
    "            os.path.dirname(os.path.realpath(idlfile)), anno.imageName)\n",
    "    while True:\n",
    "        random.shuffle(annos)\n",
    "        for anno in annos:\n",
    "            img = imread(anno.imageName)\n",
    "            im_input = image_to_h5_mx(img, image_mean, image_scaling=1.0)\n",
    "            yield im_input\n",
    "            \n",
    "        break\n",
    "\n",
    "image_mean = load_data_mean_mx(\"./data/brainwash_mean.npy\", 640,480, image_scaling=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_gen = load_idl(\"./data/brainwash/brainwash_train.idl\",image_mean, jitter = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import cv2\n",
    "max_len = 5\n",
    "\n",
    "executor = out.bind(ctx=mx.gpu(), args=arg_dict)\n",
    "e2eExcutor = namedtuple(\"e2eExcutor\",['executor','data','lstm_mem_seed','lstm_hidden_seed','bbox', 'conf', 'arg_dict'])\n",
    "\n",
    "timeExcutor = e2eExcutor(executor = executor, \n",
    "                         data = arg_dict[\"data\"], \n",
    "                         lstm_mem_seed = arg_dict[\"lstm_mem_seed\"], \n",
    "                         lstm_hidden_seed = arg_dict[\"lstm_hidden_seed\"],\n",
    "                         bbox = executor.outputs[:max_len],\n",
    "                         conf = executor.outputs[max_len:2*max_len],\n",
    "                         arg_dict=arg_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def overlap_union(x1,y1,x2,y2,x3,y3,x4,y4):\n",
    "#     SI = max(0, min(x2,x4)-max(x1,x3)) * max(0, min(y2,y4)-max(y1,y3))\n",
    "#     SU = (x2-x1)*(y2-y1) + (x4-x3)*(y4-y3) - SI + 0.0\n",
    "#     return SI/SU\n",
    "\n",
    "def generate_rois(batch_idx,acc_rects):\n",
    "    proposals =  []\n",
    "    for rect in acc_rects:\n",
    "        left_topx = rect.cx - int(rect.width/2)\n",
    "        left_topy = rect.cy - int(rect.height/2)\n",
    "        proposals.append([batch_idx,left_topx,left_topy,left_topx+rect.width,left_topy+rect.height])\n",
    "    return proposals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.5706502669\n"
     ]
    }
   ],
   "source": [
    "# grid_width = 20\n",
    "# grid_height = 15\n",
    "# img_width = 640\n",
    "# img_height = 480\n",
    "\n",
    "start = time.clock()\n",
    "num = 0\n",
    "\n",
    "# img_set = input_gen.next()\n",
    "for i in range(500):\n",
    "#     im_input = \n",
    "    timeExcutor.lstm_mem_seed[:] = mx.nd.zeros((300,250),mx.gpu())\n",
    "    timeExcutor.lstm_hidden_seed[:] =  mx.nd.zeros((300,250),mx.gpu())\n",
    "    timeExcutor.data[:] = mx.nd.array(input_gen.next())\n",
    "\n",
    "    timeExcutor.executor.forward()\n",
    "\n",
    "    bbox_list = [timeExcutor.bbox[idx].asnumpy() for idx in range(max_len)]\n",
    "    conf_list = [timeExcutor.conf[idx].asnumpy() for idx in range(max_len)]\n",
    "\n",
    "#     all_rects = [[[] for x in range(grid_width)] for y in range(grid_height)]\n",
    "#     generate_rois()\n",
    "#     pix_per_w = img_width/grid_width\n",
    "#     pix_per_h = img_height/grid_height\n",
    "#     for n in range(len(bbox_list)):\n",
    "#         for k in range(grid_height * grid_width):\n",
    "#             #print k,n,\"k n\"\n",
    "#             y = int(k / grid_width)\n",
    "#             x = int(k % grid_width)\n",
    "#             bbox = bbox_list[n][k]\n",
    "#             conf = conf_list[n][k,1].flatten()[0]\n",
    "#             abs_cx = pix_per_w/2 + pix_per_w*x + int(bbox[0,0,0])\n",
    "#             abs_cy = pix_per_h/2 + pix_per_h*y + int(bbox[1,0,0])\n",
    "#             w = bbox[2,0,0]\n",
    "#             h = bbox[3,0,0]\n",
    "#             #print x,y\n",
    "#             all_rects[y][x].append(Rect(abs_cx,abs_cy,w,h,conf))\n",
    "#     acc_rects = stitch_rects(all_rects)\n",
    "\n",
    "\n",
    "# for rect in acc_rects:\n",
    "\n",
    "#     if rect.true_confidence < 0.6:\n",
    "#         continue\n",
    "#     cv2.rectangle(img, (rect.cx-int(rect.width/2), rect.cy-int(rect.height/2)),\\\n",
    "#      (rect.cx+int(rect.width/2), rect.cy+int(rect.height/2)),color=(0,0,255),thickness=2)\n",
    "# imsave(\"./mxnet/%i.jpg\"% i, img)\n",
    "print 500/(time.clock() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
